---
title: "Project3"
author: "Gabrielle Bartomeo, Binish Chandy, Zach Dravis, Burcu Kaniskan, Niteen Kumar, Betsy Rosalen"
date: "3/21/2018"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    number_section:  true
    theme: cerulean
    highlight:  tango
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
library(knitr)
library(tidyverse)
library(DT)
library(kableExtra)
library(lubridate)
library(janitor)
library(plotly)
library(scales)
knitr::opts_chunk$set(echo = TRUE)
```

# Importing data

The data set used in this project is [Kaggle ML and Data Science Survey 2017](https://www.kaggle.com/kaggle/kaggle-survey-2017/feed). The survey was stored in 2 different data sets:a) multiple choice items, b) free-response items. Kaggle stored each data in csv format. We dowloaded the multiple choice item survey results in csv format and placed it in our [GitHub repo](https://github.com/betsyrosalen/DATA_607_Project_3)

Importing Multiple Choice data
```{r message=FALSE ,warning=FALSE}
linkMC<-"https://raw.githubusercontent.com/betsyrosalen/DATA_607_Project_3/master/project3_master/rawdata/multipleChoiceResponses.csv"
#importing MC items
MC<-read_csv (linkMC)
dim(MC)
#lets create a unique ID variable 
MC$id <- seq.int(nrow(MC))
```

Ignore this codeImporting conversionrates data incase we want to do analyses 
```{r message=FALSE ,warning=FALSE}
# link_conversion<-"https://raw.githubusercontent.com/betsyrosalen/DATA_607_Project_3/master/project3_master/rawdata/conversionRates.csv"
# #importing MC items
# conversion<-read_csv (link_conversion)
# dim(conversion)
# #lets create a unique ID variable 
# conversion$id <- seq.int(nrow(conversion))
```


# Research Question

This project will answer this globalresearch question **Which are the most values data science skills?**
The following 6 research questions will provide answer to this global question.

# Research Question 1

What is the relationship between the most popular platforms for learning DS and X (Niteen)?
Alternatively phrased: What data science learning resources and which locations of open data are utilized by people of varying levels of education? (delete me if you need to!)

## Variables and their definition 

This section will describe the name of the variables and their labels (as reported in schema doc) and how the values were codes (etc yes, no, select all)

## Manipulating data

## Exploratory Data Analysis (EDA)

```{r}

```


# Research Question 2

Does survey takers' formal education has any relationship to the ML/DS method he or she is most excited about learning in the next year? (Binish)

## Variables and their definition

```
To do the analysis, we concentrate on two colums in the dataset -
FormalEducation and MLMethodNextYearSelect
```

This section will describe the name of the variables and their labels (as reported in schema doc) and how the values were codes (etc yes, no, select all)
```
FormalEducation : Which level of formal education have you attained?
MLMethodNextYearSelect : Which ML/DS method are you most excited about learning 
in the next year?
These questions are asked to all participants.
```

## Manipulating data

```{r}
# removing NAs as they are not meaningful
subset <- MC %>%
        filter(!is.na(FormalEducation), !is.na(MLMethodNextYearSelect)) %>%
        select(FormalEducation, MLMethodNextYearSelect) %>%
        mutate (FormalEducation=as.factor(FormalEducation)) %>%
        mutate (FormalEducation=recode_factor(FormalEducation,
                                              "Bachelor's degree"='Bachelor',
        "Some college/university study without earning a bachelor's degree"=
                                                 'College Dropout',
                                              'Doctoral degree'='Doctoral',
                                              "Master's degree"='Masters',
                                              'Professional degree'=
                                                      'Professional' ,
        'I did not complete any formal education past high school'=
                                                      'High School',
                                              'I prefer not to answer'=
                                                      'No Answer'))

```

## Exploratory Data Analysis (EDA)

```
First we plot the distribution of formal education in the dataset
```
```{r}
subset %>%
        ggplot() +
        geom_bar(mapping = aes(x = FormalEducation, y = ..prop.., group = 1, fill = FormalEducation),
                 show.legend = FALSE) +
        coord_flip()
```
```
The data set predominantly contains candidates with Master's degree.   
Now let's look at the different ML/DS methods in the dataset
```
```{r}
unique(subset$MLMethodNextYearSelect)
```
```
Now we can plot the distribution of ML/DS methods with formal education
```
```{r, fig.height = 15, fig.width = 15, fig.align = "center" , message= FALSE}
subset %>%
        ggplot() + 
        geom_bar(mapping = aes(x = MLMethodNextYearSelect, fill = MLMethodNextYearSelect)) +
                 coord_flip() + 
                 theme(legend.position="bottom")+
                 facet_wrap (~FormalEducation)+
                 theme(axis.text.x = element_text(angle = 90), legend.position = 'none') +
                 labs (x="ML Method ", y="count " , title="FormalEducation vs MLMethodNextYearSelect")
```
```
Clearly in all categories of formal education, candidates want to learn
Deep learning.

The table below shows the percentage of candidates who wants to learn
Deep learning in each formal education category.
```
```{r}
algo <- c("Deep learning")
result <- subset %>%
        group_by(FormalEducation, MLMethodNextYearSelect) %>%
        summarise(count = n()) %>%
        mutate(percentage = round(count / sum(count), 2)) %>%
        filter(MLMethodNextYearSelect %in% algo) %>%
        select(-count)
kable(result)
```

# Research Question 3

What are the most frequently used DS methods? Where is the most time spent in terms of working with data? Do either of these correlate with job title or level of education? (Zach)

## Variables and their definition 

This section will describe the name of the variables and their labels (as reported in schema doc) and how the values were codes (etc yes, no, select all)

## Manipulating data

## Exploratory Data Analysis (EDA)

```{r}

```


# Research Question 4

Is there a difference between what 'Learners' think are the important skills to learn and what employed Data Scientists say are the skills and tools they are using? (Betsy)

## Variables and their definition

This section will describe the name of the variables and their labels (as reported in schema doc) and how the values were codes (etc yes, no, select all)

## Manipulating data

## Exploratory Data Analysis (EDA)

```{r}
# Select only variables that seem most related to “Which are the most valued data science skills?”
# I May narrow down these columns even more later, but want to leave as much as possible for now
# Filter for US Only
USOnly <- MC %>%
  select(-c(56:73, 76:79, 167:196, 198:228)) %>%
  filter(Country=='United States')
```


```{r}
# Separate those employed in Data Science from those who are not.

# Filter for Employed only, TitleFit better than 'Poorly', and CodeWriters only
# Remove those that said they are "Employed by a company that doesn't perform advanced analytics"
employed <- USOnly %>%
  filter(!grepl('Not employed',EmploymentStatus), 
         TitleFit!="Poorly",
         !grepl('doesn\'t perform advanced analytics',CurrentEmployerType),
         CodeWriter=="Yes",
         JobFunctionSelect != 'Build and/or run the data infrastructure')
  
# Filter for Data Science Learners who are not employed.  
# The Survey failed to capture those who are employed and ALSO students or learners!!!  
# Didn't bother to ask employed respondents if they were also sudying Data Science.
learner <- USOnly %>%
  filter(grepl('Not employed',EmploymentStatus),
         grepl('Yes',LearningDataScience))

# Get rid of empty columns 
employed <- remove_empty_cols(employed)
learner <- remove_empty_cols(learner)
glimpse(employed)
glimpse(learner)
```

```{r}
# Take a peek at the demographics of those who are employed...
employed %>% 
  group_by(CurrentJobTitleSelect) %>%
  summarise(n())

# Need to Tidy this data so that each response is in a separate row rather than all in one
employed %>% 
  group_by(CurrentEmployerType) %>%
  summarise(n())

employed %>% 
  filter(JobFunctionSelect != 'Build and/or run the data infrastructure that your business uses for storing, analyzing, and operationalizing data') %>%
  group_by(CurrentJobTitleSelect) %>%
  summarise(n())
```

```{r}
# Take a peek at the demographics of those who are learners...
learner %>% 
  group_by(StudentStatus, LearningDataScience) %>%
  summarise(n())
```


# Research Question 5

Is there any interaction between the Kaggle survey takers' program language use (R or Python) and their recommended program languages? (e.g. R users recommending R more than Python users recommending Python) (Burcu)

## Variables and their definition 

This section will describe the name of the variables and their labels (as reported in schema doc) and how the values were codes (etc yes, no, select all)

## Manipulating data


```{r ,fig.height = 8, fig.width = 8, fig.align = "center" , message= FALSE}
dim(MC)
tb1<-MC %>%
  select (id, WorkToolsSelect) %>%
  filter (id %in% c(1:6))
   datatable(tb1)
   

#removing NAs and empty values in  column=WorkToolsSelect
df <- MC[!(MC$WorkToolsSelect == "" | is.na(MC$WorkToolsSelect)), ]
dim(df)
tb2<-df %>%
  select (id, WorkToolsSelect) %>%
  filter (id %in% c(1:6))
   datatable(tb2)

#creating a new variable called work_tools where the original column values are split 
#please note that this code will generate long data   
df1<-df %>%
  mutate(work_tools = strsplit(as.character(WorkToolsSelect), ",")) %>%
  unnest(work_tools)

  #check 
tb3<-df1 %>%
  select (id, WorkToolsSelect,work_tools) %>%
  filter (id %in% c(1:3))
   datatable(tb3)

 df2<-df1  %>%
 group_by(id, work_tools) %>%
  summarize (total_count = n())   %>%
    spread( work_tools, total_count, fill=0) 


df3<-df2 %>%
 mutate(lang_use = case_when (
               (R==1 & Python==0) ~ "Using R Only",
               (R==0 & Python==1) ~ "Using Python only",
               (R==1 & Python==1) ~ "Using Both Python and R",
               (R==0 & Python==0) ~ "Using Neither Python nor R"))%>%
  select (id, R, Python, lang_use)

tb4<-df3 %>%
filter (id %in% c(1:10))
datatable(tb4)

#computing percentages
df4<-df3 %>%
group_by(lang_use) %>%
summarize (total_count = n()) %>%
mutate(percent = ((total_count / sum(total_count)) * 100), percent=round(percent, digit=2))

 #checking
datatable(df4, colnames=c("Programming Language Survey takers use", "Count", "Percent"),class = 'cell-border stripe',caption = 'Table 1: Descriptive Statistics',options = list(pageLength = 2, dom = 'tip'))


p<-ggplot (df4, aes(x=lang_use,y=percent,fill=lang_use )) +
geom_bar(stat="identity", width =.5) +
labs (x="Language ", y="The distribution of R and Python among their users (%) " ,
      title="Bar Graph of R and Python users") +
theme(axis.text.x = element_text(angle = 90)) +
scale_y_continuous (breaks=seq(0,100,10), limits = c(0,100))

ggplotly(p)



```

Let's examine the above graph by LanguageRecommendationSelect

```{r ,fig.height = 10, fig.width = 10, fig.align = "center" , message= FALSE}

 #check 
tb5<-df1 %>%
  select (id, WorkToolsSelect,work_tools, LanguageRecommendationSelect) %>%
  filter (id %in% c(1:3))
   datatable(tb5)

 df5<-df1  %>%
 group_by(id, work_tools,LanguageRecommendationSelect) %>%
  summarize (total_count = n())   %>%
    spread( work_tools, total_count, fill=0) %>%
 mutate(lang_use = case_when (
               (R==1 & Python==0) ~ "Using R Only",
               (R==0 & Python==1) ~ "Using Python only",
               (R==1 & Python==1) ~ "Using Both Python and R",
               (R==0 & Python==0) ~ "Using Neither Python nor R"),
        lang_rec = case_when (
               (LanguageRecommendationSelect=="R") ~ "Recommending R ",
               (LanguageRecommendationSelect=="Python" ) ~ "Recommending Python ",
               (LanguageRecommendationSelect!="R" |LanguageRecommendationSelect!="Python") ~ "Recommending Neither Python nor R",
               (LanguageRecommendationSelect=="NA"|LanguageRecommendationSelect==" " ) ~ "Recommending Nothing"))%>%
select (id, R, Python, lang_use,lang_rec )

 dim(df5)
 
tb6<-df5 %>%
filter (id %in% c(1:10))
datatable(tb6)

 #computing percentages
df6<-df5 %>%
group_by(lang_use,lang_rec) %>%
summarize (total_count = n()) %>%
mutate(percent = ((total_count / sum(total_count)) * 100), percent=round(percent, digit=2))

#checking
datatable(df6, colnames=c("Programming Language Survey takers use", "Count", "Percent"),class = 'cell-border stripe',caption = 'Table 1: Descriptive Statistics',options = list(pageLength = 2, dom = 'tip'))


p1<-ggplot (df6, aes(x=lang_use,y=percent,fill=lang_use )) +
geom_bar(stat="identity", width =.5) +
labs (x="Language ", y="The distribution of R and Python among their users (%) " ,
title="Bar Graph of R and Python users and their recommended language") +
theme(axis.text.x = element_text(angle = 90)) +
scale_y_continuous (breaks=seq(0,100,10), limits = c(0,100))+
  facet_wrap(~lang_rec)+
  theme(legend.position = 'none')

ggplotly(p1)
```

## Exploratory Data Analysis (EDA)

# Research Question6

Of those receiving pay in US Dollars, is Python or R overall most profitable for a Kaggle survey taker? (Gabby)

## Variables and their definition

This section will describe the name of the variables and their labels (as reported in schema doc) and how the values were codes (etc yes, no, select all)

## Manipulating data

```{r}
RQ6 <- MC %>%
  mutate(work_tools = strsplit(as.character(WorkToolsSelect), ",")) %>% 
  unnest(work_tools)

RQ6 <- RQ6 %>%
  filter(!is.na(WorkToolsSelect)) %>%  # Filters out all columns with NA in the WorkToolsSelect column
  filter(CompensationCurrency == "USD") %>% # Makes sure to only use rows whose currency is in USD
  filter(work_tools == "Python" | work_tools == "R") %>% # The work tools are R or Python, period.
  select(id, work_tools, CompensationAmount) # Only have three rows to work with
RQ6_ids <- select(filter(as.data.frame(table(RQ6$id)), Freq == 1), Var1) # Only want people who use R or Python EXCLUSIVELY, not R and/or Python
RQ6_ids <- droplevels(RQ6_ids)$Var1 # Removed the levels so we can actually get the IDs
RQ6 <- filter(RQ6, id %in% RQ6_ids) # Only keep those rows whose id are inside of list of ids with R or Python exclusively used at work
RQ6 <- select(RQ6, -id) # No use for the ID anymore, it's done its job
RQ6$CompensationAmount <- gsub(",", "", RQ6$CompensationAmount) # Removed the commas from the compensation amount to prep for numeric transformation
RQ6$CompensationAmount <- as.numeric(RQ6$CompensationAmount) # made the column into a numeric for easier mathematical comparison and sorting
RQ6 <- filter(RQ6, CompensationAmount < 9999999) # ... let's just be a little realistic, nobody is earning more than fifteen million a year at this point in time or prior to it, and this one-dollar-off-from-a-million entry is an anomaly in the data set
rm(RQ6_ids) # remove the now-unused variable to save memory
```

## Exploratory Data Analysis (EDA)

```{r}
RQ6_boxplot <- ggplot(RQ6) +
  geom_boxplot( aes(x = factor(work_tools), 
                    y = CompensationAmount,
                    fill = factor(work_tools)
                     )
                  ) +
  scale_y_continuous(breaks=seq(0,2000000,25000)) +
  labs( x = "Programming Language",
        y = "Annual Compensation in USD",
        fill = "Programming Language")
RQ6_boxplot_ylim <- boxplot.stats(RQ6$CompensationAmount)$stats[c(1, 5)]
RQ6_boxplot <- RQ6_boxplot + coord_cartesian(ylim = RQ6_boxplot_ylim*1.05)
RQ6_boxplot
```

The average survey taker who used Python in their job made approximately \$`r formatC(colMeans(select(filter(RQ6, work_tools=="Python"),CompensationAmount))-colMeans(select(filter(RQ6, work_tools=="R"),CompensationAmount)), digits=2, format="f", big.mark=",")` more than the average survey taker who used R in their job. While R users overall had a higher base pay - to the tune of $`r formatC(quantile(select(filter(RQ6, work_tools=="R"),CompensationAmount)[[1]])["25%"]-quantile(select(filter(RQ6, work_tools=="Python"),CompensationAmount)[[1]])["25%"], digits=2, format="f", big.mark=",")` more than their Python counterparts - their ability to achieve growth in salary was noticeably stymied in comparison. Outliers aside, if the data collected is to be considered representative of the data science population, there is indication that a prospective Data Scientist should learn R first for a higher initial salary, and then learn Python to increase their chance of obtaining a job with more growth potential.
